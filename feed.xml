<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="http://vvc.github.io:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://vvc.github.io:4000/" rel="alternate" type="text/html" /><updated>2019-11-18T21:16:46-05:00</updated><id>http://vvc.github.io:4000/feed.xml</id><title type="html">Visual Vehicle Counting with machine learning</title><subtitle>Visual vehicle counting applied research project, based on machine learning and computer vision techniques. Object detection and tracking from videos.</subtitle><entry><title type="html">Results (so far)</title><link href="http://vvc.github.io:4000/docs/dev/results" rel="alternate" type="text/html" title="Results (so far)" /><published>2019-11-18T21:00:00-05:00</published><updated>2019-11-18T21:00:00-05:00</updated><id>http://vvc.github.io:4000/docs/dev/results</id><content type="html" xml:base="http://vvc.github.io:4000/docs/dev/results">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#comparison&quot; id=&quot;markdown-toc-comparison&quot;&gt;Comparison&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#custom-models-based-on-yolov3&quot; id=&quot;markdown-toc-custom-models-based-on-yolov3&quot;&gt;Custom models based on YOLOv3&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tracking-metrics&quot; id=&quot;markdown-toc-tracking-metrics&quot;&gt;Tracking metrics&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#videos&quot; id=&quot;markdown-toc-videos&quot;&gt;Videos&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#retinanet&quot; id=&quot;markdown-toc-retinanet&quot;&gt;RetinaNet&lt;/a&gt;&lt;/li&gt;
      &lt;li&gt;&lt;a href=&quot;#vvc3-yolo&quot; id=&quot;markdown-toc-vvc3-yolo&quot;&gt;VVC3 YOLO&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparison&quot;&gt;Comparison&lt;/h2&gt;
&lt;p&gt;Compare YOLOv3 and Faster R-CNN with retraining.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/avg_precision.png&quot; alt=&quot;Average counting precision&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/avg_time.png&quot; alt=&quot;Average frame time&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/fps.png&quot; alt=&quot;FPS&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;custom-models-based-on-yolov3&quot;&gt;Custom models based on YOLOv3&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/assets/img/TensorBoard val_loss.png&quot; alt=&quot;vvc models&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/img/architecture_vvc1.png&quot;&gt;vvc1&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/img/architecture_vvc2.png&quot;&gt;vvc2&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/img/architecture_vvc3.png&quot;&gt;vvc3&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;tracking-metrics&quot;&gt;Tracking metrics&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Detector&lt;/th&gt;
      &lt;th&gt;Tracker&lt;/th&gt;
      &lt;th&gt;IDF1&lt;/th&gt;
      &lt;th&gt;IDP&lt;/th&gt;
      &lt;th&gt;IDR&lt;/th&gt;
      &lt;th&gt;Rcll&lt;/th&gt;
      &lt;th&gt;Prcn&lt;/th&gt;
      &lt;th&gt;GT&lt;/th&gt;
      &lt;th&gt;MT&lt;/th&gt;
      &lt;th&gt;PT&lt;/th&gt;
      &lt;th&gt;ML&lt;/th&gt;
      &lt;th&gt;FP&lt;/th&gt;
      &lt;th&gt;FN&lt;/th&gt;
      &lt;th&gt;IDs&lt;/th&gt;
      &lt;th&gt;FM&lt;/th&gt;
      &lt;th&gt;MOTA&lt;/th&gt;
      &lt;th&gt;MOTP&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;frcnn-resnet50&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;3,0%&lt;/td&gt;
      &lt;td&gt;16,3%&lt;/td&gt;
      &lt;td&gt;1,6%&lt;/td&gt;
      &lt;td&gt;3,0%&lt;/td&gt;
      &lt;td&gt;29,8%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;1007&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;-5,1%&lt;/td&gt;
      &lt;td&gt;376&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;frcnn-resnet50-transfer&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;5,6%&lt;/td&gt;
      &lt;td&gt;23,2%&lt;/td&gt;
      &lt;td&gt;3,2%&lt;/td&gt;
      &lt;td&gt;6,6%&lt;/td&gt;
      &lt;td&gt;48,6%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;73&lt;/td&gt;
      &lt;td&gt;969&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;-2,1%&lt;/td&gt;
      &lt;td&gt;376&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;YOLOv3&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;5,2%&lt;/td&gt;
      &lt;td&gt;7,5%&lt;/td&gt;
      &lt;td&gt;3,9%&lt;/td&gt;
      &lt;td&gt;9,2%&lt;/td&gt;
      &lt;td&gt;17,3%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;454&lt;/td&gt;
      &lt;td&gt;943&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;-37,0%&lt;/td&gt;
      &lt;td&gt;367&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;YOLOv3-transfer&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;3,8%&lt;/td&gt;
      &lt;td&gt;7,5%&lt;/td&gt;
      &lt;td&gt;2,5%&lt;/td&gt;
      &lt;td&gt;4,4%&lt;/td&gt;
      &lt;td&gt;13,3%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;299&lt;/td&gt;
      &lt;td&gt;992&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;-25,8%&lt;/td&gt;
      &lt;td&gt;415&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;yolo3-prunned&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;0,0%&lt;/td&gt;
      &lt;td&gt;0,0%&lt;/td&gt;
      &lt;td&gt;0,0%&lt;/td&gt;
      &lt;td&gt;0,0%&lt;/td&gt;
      &lt;td&gt;0,0%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;59&lt;/td&gt;
      &lt;td&gt;1038&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-5,7%&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;YOLOv3-tiny&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;3,2%&lt;/td&gt;
      &lt;td&gt;19,4%&lt;/td&gt;
      &lt;td&gt;1,7%&lt;/td&gt;
      &lt;td&gt;3,1%&lt;/td&gt;
      &lt;td&gt;34,4%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;61&lt;/td&gt;
      &lt;td&gt;1006&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;-3,6%&lt;/td&gt;
      &lt;td&gt;378&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;YOLOv3-tiny-transfer&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;vvc1-yolov3&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;vvc2-yolov3&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
      &lt;td&gt; &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;vvc3-yolov3&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;0,2%&lt;/td&gt;
      &lt;td&gt;16,7%&lt;/td&gt;
      &lt;td&gt;0,1%&lt;/td&gt;
      &lt;td&gt;0,1%&lt;/td&gt;
      &lt;td&gt;16,7%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;1037&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;-0,4%&lt;/td&gt;
      &lt;td&gt;306&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;RetinaNet-ResNet50&lt;/td&gt;
      &lt;td&gt;PatientIOU&lt;/td&gt;
      &lt;td&gt;10,8%&lt;/td&gt;
      &lt;td&gt;23,1%&lt;/td&gt;
      &lt;td&gt;7,0%&lt;/td&gt;
      &lt;td&gt;12,3%&lt;/td&gt;
      &lt;td&gt;40,5%&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;188&lt;/td&gt;
      &lt;td&gt;910&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;-7,2%&lt;/td&gt;
      &lt;td&gt;339&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;videos&quot;&gt;Videos&lt;/h2&gt;

&lt;h3 id=&quot;retinanet&quot;&gt;RetinaNet&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;MOV_0861&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/HThOxUQf288&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;CL 53 X CRA 60 910-911&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/r8R_OnOATAA&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&quot;vvc3-yolo&quot;&gt;VVC3 YOLO&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;MOV_0861&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/_cLdLE79Vz0&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;CL 53 X CRA 60 910-911&lt;/strong&gt;&lt;/p&gt;

&lt;div&gt;
&lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/ZdKkqdELNfs&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Thesis</title><link href="http://vvc.github.io:4000/docs/thesis" rel="alternate" type="text/html" title="Thesis" /><published>2018-12-11T12:00:00-05:00</published><updated>2018-12-11T12:00:00-05:00</updated><id>http://vvc.github.io:4000/docs/thesis</id><content type="html" xml:base="http://vvc.github.io:4000/docs/thesis">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#objectives&quot; id=&quot;markdown-toc-objectives&quot;&gt;Objectives&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;objectives&quot;&gt;Objectives&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;General objective&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Desarrollar un sistema para el conteo de vehículos que utilice como entrada secuencias de vídeo y esté basado en técnicas de visión por computador y aprendizaje de máquina&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Specific objectives&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Determinar las características que definen la robustez de un método de detección cuando la perspectiva de los vehículo es cambia en cada secuencia de vídeo&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Diseñar e implementar un método para la detección de vehículos en imágenes tomadas de cámaras de vigilancia&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Diseñar e implementar un método para el seguimiento de vehículos en secuencias de vídeo tomadas por cámaras de vigilancia&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Desarrollar un sistema de software que integre los métodos de detección y seguimiento para el conteo de vehículos en secuencias de vídeo tomadas por cámaras de vigilancia&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;em&gt;Evaluar el sistema en un conjunto de videos recolectados desde cámaras de vigilancia de la Secretaría de Movilidad de Bogotá&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Deep learning resources</title><link href="http://vvc.github.io:4000/others/resources" rel="alternate" type="text/html" title="Deep learning resources" /><published>2018-10-05T00:28:34-05:00</published><updated>2018-10-05T00:28:34-05:00</updated><id>http://vvc.github.io:4000/others/resources</id><content type="html" xml:base="http://vvc.github.io:4000/others/resources">&lt;!-- TOC depthFrom:1 depthTo:6 withLinks:1 updateOnSave:1 orderedList:0 --&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;#commercial-software&quot;&gt;Commercial software&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- /TOC --&gt;

&lt;h1 id=&quot;commercial-software&quot;&gt;Commercial software&lt;/h1&gt;

&lt;p&gt;&lt;a href=&quot;https://aws.amazon.com/rekognition/video-features/&quot;&gt;Amazon Rekognition video&lt;/a&gt;: It’s a service for object and face detection and recognition on videos. Also it can track people. To use the service you need a credit card, even for the free tier. &lt;a href=&quot;https://techcrunch.com/2018/07/26/aclu-says-amazon-facial-recognition-associated-congress-members-with-mugshots/&quot;&gt;ACLU says Amazon facial recognition associated Congress members with mugshots.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://software.intel.com/openvino-toolkit&quot;&gt;Intel OpenVINO&lt;/a&gt; (formerly the Intel Computer Vision SDK), is a toolkit that enables Deep Learning inference for Computer Vision. It only works on CPU, GPU an FPGA Intel hardware.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Data sets</title><link href="http://vvc.github.io:4000/docs/dev/data-sets" rel="alternate" type="text/html" title="Data sets" /><published>2018-09-20T00:00:00-05:00</published><updated>2018-09-20T00:00:00-05:00</updated><id>http://vvc.github.io:4000/docs/dev/data-sets</id><content type="html" xml:base="http://vvc.github.io:4000/docs/dev/data-sets">&lt;ul id=&quot;markdown-toc&quot;&gt;
  &lt;li&gt;&lt;a href=&quot;#bogotá-videos&quot; id=&quot;markdown-toc-bogotá-videos&quot;&gt;Bogotá videos&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#image-data-sets&quot; id=&quot;markdown-toc-image-data-sets&quot;&gt;Image data sets&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#trancos-2015&quot; id=&quot;markdown-toc-trancos-2015&quot;&gt;TRANCOS 2015&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;#tagging-tools&quot; id=&quot;markdown-toc-tagging-tools&quot;&gt;Tagging tools&lt;/a&gt;    &lt;ul&gt;
      &lt;li&gt;&lt;a href=&quot;#vott-visual-object-tagging-tool&quot; id=&quot;markdown-toc-vott-visual-object-tagging-tool&quot;&gt;VoTT: Visual Object Tagging Tool&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bogotá-videos&quot;&gt;Bogotá videos&lt;/h2&gt;

&lt;p&gt;Videos obtained from the Undersecretary of Mobility Services.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://mega.nz/#F!2lwy0QxJ!MCx5X7fKRqJqhj99QJNRog&quot;&gt;Videos of Bogotá&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.simur.gov.co/SimurMapaMovilidadWA/mapamovilidad&quot;&gt;Cameras location&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Other links:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.movilidadbogota.gov.co/web/organigrama&quot;&gt;SDM Organization chart&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://sideap.serviciocivil.gov.co/sideap/faces/directorioServidores.xhtml?idEntidad=113&quot;&gt;Directorio Servidores Públicos y Contratistas del Distrito &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.movilidadbogota.gov.co/web/sites/default/files/DIRECTORIO%20DE%20FUNCIONARIOS%2017042018%20V.6.pdf&quot;&gt;Directorio funcionarios SDM&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;image-data-sets&quot;&gt;Image data sets&lt;/h2&gt;

&lt;h3 id=&quot;trancos-2015&quot;&gt;&lt;a href=&quot;http://agamenon.tsc.uah.es/Personales/rlopez/data/trancos/&quot;&gt;TRANCOS 2015&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;Data set with images from “Dirección General de Tráfico de España”. The images come from real cameras, but they are separated in time from several minutes. The annotations are not bounding boxes, just one dot for vehicle.&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Original&lt;/th&gt;
      &lt;th&gt;Annotation&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;img src=&quot;/assets/img/trancos_1.jpg&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
      &lt;td&gt;&lt;img src=&quot;/assets/img/trancos_1_dots.png&quot; alt=&quot;&quot; /&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can access directly to the images from here:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.dgt.es/es/el-trafico/camaras-de-trafico/&quot;&gt;http://www.dgt.es/es/el-trafico/camaras-de-trafico/&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://infocar.dgt.es/etraffic/data/camaras/872.jpg&quot;&gt;http://infocar.dgt.es/etraffic/data/camaras/872.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://infocar.dgt.es/etraffic/data/camaras/44.jpg&quot;&gt;http://infocar.dgt.es/etraffic/data/camaras/44.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://infocar.dgt.es/etraffic/data/camaras/11.jpg&quot;&gt;http://infocar.dgt.es/etraffic/data/camaras/11.jpg&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://infocar.dgt.es/etraffic/data/camaras/161042.jpg&quot;&gt;http://infocar.dgt.es/etraffic/data/camaras/161042.jpg&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tagging-tools&quot;&gt;Tagging tools&lt;/h2&gt;

&lt;h3 id=&quot;vott-visual-object-tagging-tool&quot;&gt;&lt;a href=&quot;https://github.com/Microsoft/VoTT&quot;&gt;VoTT: Visual Object Tagging Tool&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;It works on mp4 videos only. You can use ffmpeg to convert videos from other formats.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;ffmpeg &lt;span class=&quot;nt&quot;&gt;-i&lt;/span&gt; 910-911.avi 910-911.mp4&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;</content><author><name></name></author><summary type="html"></summary></entry></feed>